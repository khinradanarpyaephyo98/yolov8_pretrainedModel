{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZrz8m4kT8z1"
      },
      "outputs": [],
      "source": [
        "#Install Libraries \n",
        "!pip install -q —upgrade keras-cv\n",
        "!pip install -q —upgrade keras  # Upgrade to Keras 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbzQbYjsUkxP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
        "\n",
        "from tensorflow import data as tf_data\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "import keras_cv\n",
        "import numpy as np\n",
        "from keras_cv import bounding_box\n",
        "import os\n",
        "from keras_cv import visualization\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxnW6LvyUqDj"
      },
      "source": [
        "**UPLOAD PRE-TRAINED MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbAmApVyUuOb"
      },
      "outputs": [],
      "source": [
        "pretrained_model = keras_cv.models.YOLOV8Detector.from_preset(\n",
        "    \"yolo_v8_m_pascalvoc\", bounding_box_format=\"xywh\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHOKS4ScUwR_"
      },
      "outputs": [],
      "source": [
        "filepath = keras.utils.get_file(origin=\"https://i.imgur.com/gCNcJJI.jpg\")\n",
        "image = keras.utils.load_img(filepath)\n",
        "image = np.array(image)\n",
        "\n",
        "visualization.plot_image_gallery(\n",
        "    np.array([image]),\n",
        "    value_range=(0, 255),\n",
        "    rows=1,\n",
        "    cols=1,\n",
        "    scale=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rGdoKqFU-T_"
      },
      "outputs": [],
      "source": [
        "inference_resizing = keras_cv.layers.Resizing(\n",
        "    640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZZB_PXaVAY8"
      },
      "outputs": [],
      "source": [
        "image_batch = inference_resizing([image])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOUQnQ8rVC2q"
      },
      "outputs": [],
      "source": [
        "class_ids = [\n",
        "    \"Aeroplane\",\n",
        "    \"Bicycle\",\n",
        "    \"Bird\",\n",
        "    \"Boat\",\n",
        "    \"Bottle\",\n",
        "    \"Bus\",\n",
        "    \"Car\",\n",
        "    \"Cat\",\n",
        "    \"Chair\",\n",
        "    \"Cow\",\n",
        "    \"Dining Table\",\n",
        "    \"Dog\",\n",
        "    \"Horse\",\n",
        "    \"Motorbike\",\n",
        "    \"Person\",\n",
        "    \"Potted Plant\",\n",
        "    \"Sheep\",\n",
        "    \"Sofa\",\n",
        "    \"Train\",\n",
        "    \"Tvmonitor\",\n",
        "    \"Total\",\n",
        "]\n",
        "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqFOzpIQYJ03"
      },
      "outputs": [],
      "source": [
        "y_pred = pretrained_model.predict(image_batch)\n",
        "# y_pred is a bounding box Tensor:\n",
        "# {\"classes\": ..., boxes\": ...}\n",
        "visualization.plot_bounding_box_gallery(\n",
        "    image_batch,\n",
        "    value_range=(0, 255),\n",
        "    rows=1,\n",
        "    cols=1,\n",
        "    y_pred=y_pred,\n",
        "    scale=5,\n",
        "    font_scale=0.7,\n",
        "    bounding_box_format=\"xywh\",\n",
        "    class_mapping=class_mapping,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GQEEAviZTIf"
      },
      "source": [
        "**To test with extracted images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dumKru5JZRpP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "count=0\n",
        "for filename in os.listdir(\"TestData\"):\n",
        "    f=os.path.join(\"TestData\", filename)\n",
        "    #check if there is file\n",
        "    if os.path.isfile(f):\n",
        "        print(\"f\",f)\n",
        "        image1=keras.utils.load_img(f)\n",
        "        image2=np.array(image1)\n",
        "        image_batch = inference_resizing([image2])\n",
        "        y_pred = pretrained_model.predict(image_batch)\n",
        "        # y_pred is a bounding box Tensor:\n",
        "        # {\"classes\": ..., boxes\": ...}\n",
        "        outputimg=visualization.plot_bounding_box_gallery(\n",
        "            image_batch,\n",
        "            value_range=(0, 255),\n",
        "            rows=1,\n",
        "            cols=1,\n",
        "            y_pred=y_pred,\n",
        "            scale=5,\n",
        "            font_scale=0.7,\n",
        "            bounding_box_format=\"xywh\",\n",
        "            class_mapping=class_mapping,\n",
        "        )\n",
        "        filename = \"Output/\"+Path(f).stem+\".png\"\n",
        "        outputimg.savefig(filename)\n",
        "    count+=1\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
